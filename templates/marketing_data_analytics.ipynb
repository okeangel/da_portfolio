{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ce343d",
   "metadata": {},
   "source": [
    "# Анализ коммерческих показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "URL = 'https://code.s3.yandex.net/datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907a5a2",
   "metadata": {},
   "source": [
    "## Метрики и воронки\n",
    "\n",
    "Процесс продаж: потребитель -(привлечение)-> посетитель -(продажа)-> покупатель .\n",
    "\n",
    "### Конверсия\n",
    "\n",
    "Конверсия — это доля людей, перешедших из одного состояния в другое.\n",
    "\n",
    "### Воронка действий\n",
    "\n",
    "Воронка действий - это схема, в которой ожидаемые (нужные для коммерции) действия пользователя расставлены так, что каждое действие - это переход из этапа в этап.\n",
    "\n",
    "\"Закрытие сделки\" - это проход всех шагов, завершая оплатой. Начинается сделка с момента, когда мы сделали шаг навстречу потребителю - например, показав ему рекламу.\n",
    "\n",
    "Воронка действий — это способ отобразить:\n",
    "- путь клиента до совершения нужного нам действия;\n",
    "- долю людей, которые «не отваливаются» и переходят на каждый следующий этап этого пути.\n",
    "\n",
    "#### Как построить воронку?\n",
    "\n",
    "Нужно определить шаги. Например:\n",
    "\n",
    "- Зайти на главную страницу магазина;\n",
    "- Перейти на страницу товара;\n",
    "- Добавить товар в корзину;\n",
    "- Перейти на страницу оформления заказа;\n",
    "- Оплатить заказ (целевое действие - совершение которого пользователем и есть наша цель).\n",
    "\n",
    "![Визуальная воронка](https://pictures.s3.yandex.net/resources/voronka_1620303482.jpg)\n",
    "![Пример воронки продаж](https://pictures.s3.yandex.net/resources/etap_1620303427.jpg)\n",
    "![Воронка с конверсиями](https://pictures.s3.yandex.net/resources/konversiya_1620303530.png)\n",
    "\n",
    "Вот воронка, в которой пользователь может пропускать шаги. В результате шаг, который можно пропустить, исполнили меньше пользователей, чем следующий, но обязательный.\n",
    "\n",
    "![](https://pictures.s3.yandex.net/resources/konversiya3_1620304024.png)\n",
    "\n",
    "Чем меньше шагов - тем лучше для пользователя, а значит - тем привлекательней для него, а значит - больше выручка.\n",
    "\n",
    "### Воронка лидов (маркетинговая)\n",
    "\n",
    "Фирма желает узнать, сколько будет покупателей на товар. Она открывает специальную страницу, где принимаются заявки на покупку - это \"лендинг\". Пользователь видит рекламу - переходит на лендинг - оставляет контакты.\n",
    "\n",
    "Заинтересованный пользователь - это \"лид\". Его контакты - это тоже \"лид\" (второе значение). Процесс поиска заинтересованных людей (\"лидов\"), привлечение их (чтобы они сами интересовались) или сбор их контактов (чтобы мы им сообщили) - это \"лидогенерация\".\n",
    "\n",
    "Лид можно превратить в заказчика. Когда соберётся нужное число пользователей - им предложат оформить покупку.\n",
    "\n",
    "Цель маркетологов — собрать как можно больше лидов.\n",
    "\n",
    "Шаги воронки:\n",
    "- Показы. Сколько раз показывали баннеры (данные из рекламной системы);\n",
    "- Переходы. Различают подэтапа:\n",
    "  - Клики. Сколько пользователей по этим баннерам кликнуло (данные из рекламной системы);\n",
    "  - Посещения (переходы). Сколько кликнувших попали на лендинг (данные из веб-аналитической системы);\n",
    "- Регистрации. Сколько посетителей оставили компании свои данные (данные из веб-аналитической системы).\n",
    "\n",
    "Данные о показах и кликах получают из рекламных систем. Информацию о переходах на лендинг и регистрациях — из системы аналитики сайта (веб-аналитики, типа Яндекс.Метрики).\n",
    "\n",
    "Маркетинговые данные чаще всего агрегированы — отражают общее количество показов, переходов и регистраций за каждый день.\n",
    "\n",
    "О переходе. Клик, который регистрируется в рекламной аналитике - должен автоматически привести к посещению рекламируемой страницы. Таким образом, количество кликов в рекламном отчёте должно точно совпасть с количеством переходов из этой рекламы в веб-отчёте (отчёте о посетителях страницы). Если не совпало - значит, есть техническая проблема, которую надо решить.\n",
    "\n",
    "Системы анализа посещений веб-страниц записывают, какая страница \"привела\" к посещению. В случае прямого входа (по адресу, из закладки) источник посещения будет не известен. Реферал - это как раз тот, кто привёл на страницу. Обычно реферала узнают по коду в \"реферальной ссылке\" - это URL, к которому присобачено кодовое обозначение того, кто привёл клиента. Пользователь кликает на рекламу - де факто на реферальную ссылку - браузер запрашивает страницу по этой ссылке - сервер читает ссылку, и видит в тексте ссылки, какое объявление сработало (и у кого оно размещено).\n",
    "\n",
    "Как только все данные собраны, можно считать конверсии.\n",
    "\n",
    "### CTR Click-Through Rate\n",
    "\n",
    "Клики (переходы) / показы.\n",
    "\n",
    "### CR Convertion Rate\n",
    "\n",
    "Регистрации / переходы (клики)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c55121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# загружаем статистику рекламы\n",
    "ad_data = pd.read_csv(URL + 'ad_data.csv')\n",
    "ad_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cc81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и статистику сайта\n",
    "site_data = pd.read_csv(URL + 'site_data.csv')\n",
    "site_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549f71a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# объединяем данные за одни и те же даты\n",
    "funnel = pd.merge(ad_data, site_data, on='date')\n",
    "\n",
    "# рассчитываем конверсии\n",
    "funnel['ctr, %'] = funnel['clicks'] / funnel['impressions'] * 100\n",
    "funnel['cr, %'] = funnel ['registrations'] / funnel['clicks'] * 100\n",
    "\n",
    "funnel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae0afd9",
   "metadata": {},
   "source": [
    "#### Вычисление конверсий за несколько периодов вместе\n",
    "\n",
    "Например, за неделю:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# устанавливает подходящий тип данных для дат\n",
    "funnel['date'] = pd.to_datetime(funnel['date'])\n",
    "# теперь у каждой даты легко узнать номер недели в году\n",
    "funnel['week'] = funnel['date'].dt.isocalendar().week\n",
    "\n",
    "# создаём группы по неделям\n",
    "funnel_weekly = funnel.groupby('week')[[\n",
    "    # оставляем в каждой группе только три колонки\n",
    "    'impressions', 'clicks', 'registrations'\n",
    "]].sum()  # и записываем в каждой колонке сумму за всю неделю\n",
    "\n",
    "# добавляем данные - CTR и CR для каждой недели\n",
    "funnel_weekly['ctr, %'] = funnel_weekly['clicks'] / funnel_weekly['impressions'] * 100\n",
    "funnel_weekly['cr, %'] = funnel_weekly['registrations'] / funnel_weekly['clicks'] * 100\n",
    "\n",
    "funnel_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b76a5",
   "metadata": {},
   "source": [
    "И за месяц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_data = pd.read_csv(URL + 'ad_data_2.csv')\n",
    "site_data = pd.read_csv(URL + 'site_data_2.csv')\n",
    "\n",
    "# соединяем данные за каждую дату\n",
    "funnel_daily = pd.merge(ad_data, site_data, on='date')\n",
    "# добавляем CTR и CR за каждую дату\n",
    "funnel_daily['ctr, %'] = funnel_daily['clicks'] / funnel_daily['impressions'] * 100\n",
    "funnel_daily['cr, %'] = funnel_daily['registrations'] / funnel_daily['clicks'] * 100\n",
    "\n",
    "# добавляем номер недели и месяца у каждой даты\n",
    "funnel_daily['date'] = pd.to_datetime(funnel_daily['date'])\n",
    "funnel_daily['week'] = funnel_daily['date'].dt.isocalendar().week\n",
    "funnel_daily['month'] = funnel_daily['date'].dt.month\n",
    "\n",
    "# создаём сводку по неделям\n",
    "funnel_weekly = funnel_daily.groupby('week')[['impressions', 'clicks', 'registrations']].sum()\n",
    "funnel_weekly['ctr, %'] = funnel_weekly['clicks'] / funnel_weekly['impressions'] * 100\n",
    "funnel_weekly['cr, %'] = funnel_weekly['registrations'] / funnel_weekly['clicks'] * 100\n",
    "\n",
    "display(funnel_weekly)\n",
    "\n",
    "# создаём сводку по месяцам\n",
    "funnel_monthly = funnel_daily.groupby('month')[['impressions', 'clicks', 'registrations']].sum()\n",
    "funnel_monthly['ctr, %'] = funnel_monthly['clicks'] / funnel_monthly['impressions'] * 100\n",
    "funnel_monthly['cr, %'] = funnel_monthly['registrations'] / funnel_monthly['clicks'] * 100\n",
    "\n",
    "display(funnel_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fa6f5",
   "metadata": {},
   "source": [
    "### Воронка пользователей в сервисе (\"продуктовая\")\n",
    "\n",
    "Она показывает, что делают пользователи на сайте или в приложении.\n",
    "\n",
    "Продуктовые данные обычно «сырые»: каждая строчка в таблице — это отдельное событие. Например, «пользователь 42 открыл страницу сайта».\n",
    "\n",
    "Например, интернет-магазин хочет увеличить выручку.\n",
    "\n",
    "Покупатели проходят четыре этапа:\n",
    "- Заходят на сайт;\n",
    "- Добавляют в корзину товары;\n",
    "- Оформляют заказ;\n",
    "- Оплачивают покупку.\n",
    "\n",
    "Чтобы выявить действия, которые влияют на количество продаж, построим продуктовую воронку и проанализируем, сколько пользователей доходят до каждого этапа.\n",
    "\n",
    "Логи событий отличаются на разных сайтах, но есть три обязательных столбца:\n",
    "\n",
    "- название события,\n",
    "- дата и время события,\n",
    "- идентификатор пользователя, с которым это событие произошло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(URL + 'product_funnel_demo.csv')\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b0725",
   "metadata": {},
   "source": [
    "Самый простой способ построить воронку — посчитать, сколько раз наступило каждое событие. Сгруппируем датафрейм по полю event_name и посчитаем строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db216f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_count = events.groupby('event_name').agg({'uid': 'count'})\n",
    "\n",
    "events_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc302b0",
   "metadata": {},
   "source": [
    "Событие pageview произошло 1249 раз, а событие add_to_cart — 1311 раз. Возможно, товар можно добавить, не просматривая одну страницу, а прямо с текущей.\n",
    "\n",
    "Помни! Каждая строка - это некая сущность. Она должна быть уникальной. Например, с помощью \"ключа\" или ID. Вот тот предмет, чьи ID в таблице всегда _уникальны_ (не повторяются) - тот и есть главное содержимое таблицы. Если в таблице _уникальны_ ID действий (например, таймстампы) - то **это таблица действий**, а не пользователей. В ней, даже сосчитав **количество `user_id`**, ты получаешь **не количество пользователей**, а количество действий.\n",
    "\n",
    "Как же узнать количество пользователей, которые совершали действие (один раз или много)? Считать количество _уникальных_ ID пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_count = (\n",
    "    events.groupby('event_name')\n",
    "    # подсчитываем именно количество пользователей (уникальных) в группе,\n",
    "    .agg({'uid': 'nunique'})\n",
    "    # сортируем по кол-ву пользователей\n",
    "    .sort_values(by='uid', ascending=False)\n",
    ")\n",
    "\n",
    "users_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9995ec",
   "metadata": {},
   "source": [
    "Теперь видно, сколько человек дошли до каждого этапа продуктовой воронки.\n",
    "\n",
    "- Примерно 74% зашедших на сайт (смотревших хоть одну страницу, pageview) пользователей добавили товар в корзину.\n",
    "- Только 34% добавивших товар в корзину перешли к оплате.\n",
    "- И лишь 36% начавших оформлять заказ оплатили его.\n",
    "\n",
    "Можно попробовать это исправить: например, разослать персональные скидки пользователям, которые добавили товар в корзину, но не перешли к оформлению, а также улучшить страницу оплаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5801e0",
   "metadata": {},
   "source": [
    "## Анализ по когортам\n",
    "\n",
    "### Агрегация профилей пользователя - источника перехода, первое посещение, регистрация, первый платёж\n",
    "\n",
    "Обычно чем больше клиентов, тем лучше для бизнеса. Задача бизнеса - принять такие решения, исполнить такие длействия, чтобы как можно больше людей принесли деньги.\n",
    "\n",
    "Разные люди реагируют по разному. В идеале, лучше всего подстраиваться под каждого потребителя индивидуально. Там, где это ещё не достигнуто - всё равно полезно разделить людей на категории (\"когорты\"), чтобы каждая когорта включала людей, которые одинаково реагируют на одинаковые стимулы. Благодаря этому мы будем делать что-то для тех, кому это нравится, и не делать для тех, кому не нравится. Все довольны. Доходы выше, чем если бы мы действовали одинаково для всех.\n",
    "\n",
    "5 шагов успешного когортного анализа:\n",
    "1. Определи, какой вопрос нужно ответить. Главное в анализе - получить руководство к действию.\n",
    "2. Определи метрики, отоорые могут помочь ответить на вопрос. \n",
    "3. Определи, какой признак брать, чтобюы делить на когорты. Желатльно, чтобы коготрты кардинально различались.\n",
    "4. Проведи анализ. Визуализируй.\n",
    "5. Убедьсь, что результаты имеют смысл. Наверное, посоветуйся со специалистом и с отвлечёнными людьми.\n",
    "\n",
    "Заполучить клиентов можно двумя способами:\n",
    "- Бесплатно. Это так называемая «органика» — пользователи, которые нашли компанию самостоятельно: по рекомендации, через поиск или случайно.\n",
    "- Платно. Компания вкладывает деньги в рекламу. Рекламным сетям можно платить за каждый просмотр объявления пользователем, за клик по нему или даже за целевое действие — переход на сайт или скачивание приложения. В последнем случае бизнес фактически «покупает» новых клиентов.\n",
    "\n",
    "Но где инвестиции, там и риски. «Купленные» клиенты могут ничего не купить. Или приобрести самый дешёвый товар и исчезнуть навсегда. Поэтому бизнес стремится привлечь самых «качественных» клиентов — тех, кто принесёт больше всего денег.\n",
    "\n",
    "Риски платных клиентов - они могут не окупиться (не заплатить, не сделать\n",
    "покупки или сделать слишком маленькую покупку).\n",
    "\n",
    "Качественный привлечённый клиент - это такой, который:\n",
    "- долго с компанией,\n",
    "- рекомендует и упоминает её,\n",
    "- часто покупает,\n",
    "- много тратит,\n",
    "- мало расходов на привлечение,\n",
    "- мало расходов на удержание.\n",
    "\n",
    "Чтобы оценить качество клиентов, применяют когортный анализ.\n",
    "\n",
    "В основном аналитик желает увидеть:\n",
    "- какие когорты охотнее делают нужное действие (например, платят), чтобы затем привлекать людей именно в эту когорту, с этими признаками;\n",
    "- как изменяется намерение к нужному действию: как часто его повторяют, какие ещё тренды есть кроме целевого. Для этого изучают когорты, составленные по времени. И изучают их поведение отдельно от остальных, как и через сколько времени люди меняют поведение и отношение. Чтобы не смешивать только что пришедшего пользователя и давно освоившегося, недавно ещё бывшего на сайте, и уже давно покинувшего.\n",
    "\n",
    "Когортный анализ редко применяют для прогнозирования поведения пользователей, ведь в будущем на него могут повлиять внешние, ещё не известные факторы.\n",
    "\n",
    "#### Основные правила\n",
    "\n",
    "Аналитики называют группы (категории) пользователей \"когортами\". Участников\n",
    "когорты объединяет общий признак. Примеры: впервые посетившие страницу,\n",
    "участвующие в программе лояльности, пользователи приложения.\n",
    "\n",
    "Чем как объединяют учатников в когорту:\n",
    "- входят в один временной промежуток, и связаны однотипными событиями.\n",
    "- Дополнительные (персональные) признаки: возраст, пол, профессия, локация,\n",
    "особенности поведения.\n",
    "\n",
    "Например: событие - первое посещение сайта, промежуток - в апреле. Когорту\n",
    "можно назвать \"пользователи, впервые посетившие сайт в апреле\".\n",
    "А можно ввести доп признак: \"пользователи из Москвы\".\n",
    "\n",
    "#### Типичный набор данных пользователя\n",
    "\n",
    "Все системы бизнес-аналитики собирают примерно один и тот же минимальный набор информации о пользователях. Есть две большие группы данных: журнал посещений сайта пользователями, то есть пользовательских сессий, и журнал покупок.\n",
    "\n",
    "##### Данные журнала пользовательских сессий\n",
    "\n",
    "- `user_id` - уникальный идентификатор пользователя;\n",
    "- `session_start` - дата начала сессии;\n",
    "- `session_duration` или `session_end` - дата окончания или длительность сессии;\n",
    "- `device` — устройство, с которого пользователь заходил на сайт;\n",
    "- `region` — географическое положение в момент посещения сайта;\n",
    "- `channel` —  рекламный канал, источник переходов или иной ресурс, с которого пользователь перешёл на сайт.\n",
    "\n",
    "##### Данные журнала покупок\n",
    "\n",
    "- уникальный идентификатор пользователя,\n",
    "- дата совершения покупки,\n",
    "- сумма покупки.\n",
    "\n",
    "#### Создание профилей пользователей\n",
    "\n",
    "1. Загрузить данные журнала посещений.\n",
    "2. Для каждого пользователя определить дату и время первой сессии.\n",
    "3. Для каждого пользователя определить соответствующие задаче параметры первой сессии. Например, источник перехода на сайт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем журнал сессий\n",
    "sessions = pd.read_csv(URL + 'sessions.csv')\n",
    "\n",
    "# преобразуем данные о времени для дальнейших расчётов\n",
    "sessions['session_start'] = pd.to_datetime(sessions['session_start'])\n",
    "\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(URL + 'book_orders.csv')\n",
    "orders['event_dt'] = pd.to_datetime(orders['event_dt'])\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d09a60",
   "metadata": {},
   "source": [
    "#### `get_columns_to_rename()`:\n",
    "\n",
    "- `dataframe` — датафрейм, в котором нужно обновить имена колонок,\n",
    "- `keys` - список колонок, которые нельзя переименовывать,\n",
    "- `addition` - текст, который добавим к имени,\n",
    "- `prefix` - дописать перед именем? если False - то после имени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_to_rename(dataframe,\n",
    "                          keys=['user_id', 'date', 'payer', 'dt'],\n",
    "                          addition='first',\n",
    "                          prefix=True):\n",
    "    \"\"\"Возвращает словарь замен старых имён колонок на новые.\n",
    "    \n",
    "    Служит для того, чтобы результаты обработки журнала событий\n",
    "    находились в колонках с другими именами, а не с такими же,\n",
    "    как хранятся в журнале событий.\n",
    "    \n",
    "    Это позволит объединять журналы и профили вместе,\n",
    "    и не беспокоиться о том, чтобы переименовывать колонки вручную.\n",
    "    Переименование проходит по интуитивно понятным правилам,\n",
    "    информация будет подписана более очевидным способом,\n",
    "    чем тот, что применяется в `merge()`.\n",
    "    \"\"\"\n",
    "    source_columns = [\n",
    "        x for x in dataframe.columns if not (\n",
    "            x in keys or addition in x) ]\n",
    "    \n",
    "    # и запланируем: добавить к имени каждого столбца префикс \"first_\"\n",
    "    # теперь наши названия содержательны и уникальны, они не смешаются\n",
    "    # с названиями колонок из events, когда мы будем добавлять profiles в events\n",
    "    print('Переименованные колонки:')\n",
    "    columns_to_rename = dict()\n",
    "    for name in source_columns:\n",
    "        if prefix:\n",
    "            columns_to_rename[name] = addition + '_' + name\n",
    "        else:\n",
    "            columns_to_rename[name] = name + '_' + addition\n",
    "        print(f\"'{name}' => '{columns_to_rename[name]}'\")\n",
    "    print()\n",
    "    return columns_to_rename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cecfcb",
   "metadata": {},
   "source": [
    "#### `get_profiles()`:\n",
    "\n",
    "- `events` — журнал событий,\n",
    "- `uid` - имя колонки, которая содержит ID пользователя,\n",
    "- `event_dt` - имя колонки, в которой записаны дата и время события,\n",
    "- `method` - название метода (доступного столбцам pandas), которым мы найдём значение признака пользователя.\n",
    "\n",
    "Для создания пользовательских профилей с датой первого посещения и источником перехода на сайт напишем функцию `get_profiles()`. В ней сгруппируем значения датафрейма по пользовательскому ID и применим функцию `first()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf18e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profiles(events,\n",
    "                 orders=None,\n",
    "                 uid='user_id',\n",
    "                 event_dt='event_dt',\n",
    "                 method='first'):\n",
    "    \"\"\"Возвращает профили пользователей на основе журнала событий.\n",
    "    \n",
    "    Все события группируются по пользователям. Указанным методом\n",
    "    на основе всех вариантов признака выбирается нужное значение признака.\n",
    "    Название метода дописывается в названия всеx преобразованныx колонок.\n",
    "    \"\"\"\n",
    "    # получаем словарь, какие колонки в профилях как назвать\n",
    "    columns = get_columns_to_rename(events, [uid], method)\n",
    "\n",
    "    result = (\n",
    "        # сортируем сессии по ID пользователя и дате посещения\n",
    "        events.sort_values(by=[uid, event_dt])\n",
    "        # группируем по ID\n",
    "        .groupby(uid)\n",
    "        # и находим характерные признаки пользователя\n",
    "        .agg(method)\n",
    "        # переименуем колонки, чтобы имена соответствовали содержимому\n",
    "        .rename(columns=columns)\n",
    "        # возвращаем uid из индекса в колонки\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # определяем дату первого посещения\n",
    "    # и первый день месяца, в который это посещение произошло\n",
    "    # эти данные понадобятся для когортного анализа\n",
    "    result['date'] = result[columns[event_dt]].dt.date\n",
    "    result['month'] = result[columns[event_dt]].astype('datetime64[M]')\n",
    "    \n",
    "    # Если мы дали ещё и журнал продаж...\n",
    "    if orders is not None:\n",
    "        # Это заказчик, или \"пока не определился\"?\n",
    "        # Заказчиком считаем, если хоть однажды сделал заказ.\n",
    "        # Заказ - почти всегда подразумевается \"платёж\".\n",
    "        result['payer'] = result['user_id'].isin(orders['user_id'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(URL + 'profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2092afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём профили пользователей,\n",
    "# используя записи об их посещениях и покупках\n",
    "profiles = get_profiles(sessions, orders, event_dt='session_start')\n",
    "\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaab82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отобразим, из какой страны по статистике\n",
    "# лиды становятся заказчиками чаще\n",
    "# то есть, где выше CR Conversion Rate\n",
    "display(\n",
    "    profiles.groupby('first_region')\n",
    "    .agg({'payer': 'mean'})\n",
    "    .sort_values('payer', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469740a",
   "metadata": {},
   "source": [
    "Видим, что выше всего процент плательщиков среди американцев, ниже всего - среди французов. Но разница не велика. Лучше рассмотреть больше признаков, чтобы найти таки ощутимую разницу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0303c",
   "metadata": {},
   "source": [
    "Ещё, имея готовые профили пользователей, легко узнать количество привлечённых каждым источником посетителей. Достаточно сгруппировать профили по рекламному каналу и посчитать количество уникальных ID функцией `nunique()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.groupby('first_channel').agg({'user_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29de49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiles.pivot_table(\n",
    "    index='date',  # даты первых посещений\n",
    "    columns='first_channel',  # источники переходов\n",
    "    values='user_id',  # ID пользователей\n",
    "    aggfunc='nunique'  # подсчёт уникальных значений\n",
    ").plot(figsize=(15, 5), grid=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d1733",
   "metadata": {},
   "source": [
    "### Retention Rate\n",
    "\n",
    "В цифровых сервисах когортный анализ применяют, чтобы сравнить «качество» пользователей. Один из главных критериев качества — как долго клиент остаётся с компанией. На языке метрик этот факт часто описывают двумя показателями: Retention Rate и Churn Rate.\n",
    "\n",
    "Retention Rate, или коэффициент удержания, показывает, как долго клиенты остаются с компанией. Сколько пользователей из когорты относительно их изначального числа вернулись, то есть воспользовались продуктом или услугой, в последующие периоды.\n",
    "\n",
    "Это важнейший показатель для компаний, которые зарабатывают с пользователей напрямую (интернет-магазинов или сервисов по подписке). Ведь чем дольше привлечённый клиент пользуется продуктом, тем больше потенциальная выручка.\n",
    "\n",
    "Полезен Retention Rate и для зарабатывающих на рекламе компаний — социальных сетей, поисковых систем. Чем дольше клиенты пользуются сервисом, тем больше показов рекламных объявлений можно продать.\n",
    "\n",
    "Чтобы узнать Retention Rate, нужно разделить количество активных пользователей когорты в нужный день на количество активных пользователей когорты на первый день.\n",
    "\n",
    "_Например, Retention Rate на разные даты для пользователей от 1 и 2 апреля._\n",
    "\n",
    "![Пример таблицы удержаний](https://pictures.s3.yandex.net/resources/Retention_Rate_3_1620468175.png)\n",
    "\n",
    "Лайфтайм - это срок, который существует когорта. Единица измерения лайфтайма - длине периода, на который разделены пользователи по когортам. Если когорты образованы на основе дат - то лайфтайм - это количество полных суток с момента создания когорты. Если по неделям - то количество недель. По месяцам - количество месяцев.\n",
    "\n",
    "Теперь Retention Rate разных когорт можно сравнивать напрямую. Или вычислить общий Retention Rate для разных когорт: складывать суммы из одинаковых лайфтаймов - а затем по полученному ряду сумм вычислять Retention Rate в тот или иной лайфтайм.\n",
    "\n",
    "Шаги:\n",
    "\n",
    "- Собрать таблицу событий:\n",
    "  - Объединить данные сессий с профилями.\n",
    "  - Рассчитать лайфтайм пользователя для каждой сессии.\n",
    "- Построить таблицу долей удержания:\n",
    "   - Построить таблицу удержания. То есть сводную таблицу, в которой названия строк — это даты первого посещения пользователей, названия столбцов — лайфтайм, а значения в «ячейках» — количество уникальных идентификаторов пользователей.\n",
    "   - Вычислить размеры когорт и занести результаты в отдельную таблицу.\n",
    "   - Разделить каждую «ячейку» таблицы удержания на соответствующий размер когорты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в данном случае событие - это заход на сайт, сессия\n",
    "# собираем данные о событиях: к данным о сессиях добавляем данные о профиле пользователя\n",
    "events = sessions.merge(profiles, on='user_id', how='right')\n",
    "\n",
    "# вычисляем лайфтайм каждого события в днях\n",
    "events['lifetime'] = (\n",
    "    events['session_start'] - events['first_session_start']\n",
    ").dt.days\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим таблицу удержания - сколько пользователей из когорты повторили действие в каждый лайфтайм\n",
    "retention = events.pivot_table(\n",
    "    index=['date'], columns='lifetime', values='user_id', aggfunc='nunique'\n",
    ")\n",
    "\n",
    "retention.astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9217dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисляем размеры когорт\n",
    "cohort_sizes = (\n",
    "    # Сгруппируем данные по дате первого посещения из `dt`\n",
    "    events.groupby('date')\n",
    "    # и посчитаем количество уникальных пользователей в каждой когорте,\n",
    "    # применив функцию `nunique` к столбцу `user_id`.\n",
    "    .agg({'user_id': 'nunique'})\n",
    "    # теперь это серия, которая содержит размер когорты\n",
    "    .rename(columns={'user_id': 'cohort_size'})\n",
    ")\n",
    "\n",
    "cohort_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbebfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делим данные таблицы удержания на размеры когорт\n",
    "retention_rates = retention.div(\n",
    "    cohort_sizes['cohort_size'], axis=0\n",
    ")\n",
    "\n",
    "retention_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d168a",
   "metadata": {},
   "source": [
    "#### `get_attributed_events()`\n",
    "\n",
    "- `events` - список событий,\n",
    "- `profiles` - список пользователей,\n",
    "- `uid` - название колонки с ID пользователя,\n",
    "- `event_dt` - название колонки, которая содержит время наступления события."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributed_events(source, profile_source, uid='user_id', event_dt='event_dt'):\n",
    "    \"\"\"Возвращает список событий, обогащённый данными о пользователе.\n",
    "    \n",
    "    Эти данные полезны, чтобы собирать события в группы.\n",
    "    \"\"\"\n",
    "    attr_events = source.merge(profile_source, on=uid, how='right')\n",
    "\n",
    "    # вычисляем лайфтайм каждого события в днях\n",
    "    attr_events['lifetime'] = (\n",
    "        attr_events[event_dt] - attr_events['first_' + event_dt]\n",
    "    ).dt.days\n",
    "    \n",
    "    return attr_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributed_events = get_attributed_events(\n",
    "    sessions,\n",
    "    profiles,\n",
    "    event_dt='session_start',\n",
    ")\n",
    "\n",
    "attributed_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ebade",
   "metadata": {},
   "source": [
    "#### `get_rates()`\n",
    "\n",
    "- `events` - список действий,\n",
    "- `dimensions` - список признаков, по которым разделяем на когорты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ecd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates(events,\n",
    "              kind='retention',\n",
    "              dimensions=[]):\n",
    "    \"\"\"Возвращает таблицу коэффициентов.\n",
    "    \n",
    "    Требует список действий, обогащённый признаками пользователя,\n",
    "    совершившего действия.\n",
    "    И тип результата:\n",
    "    - удержание (повторяющиеся действия, сумма за лайфтайм);\n",
    "    - конверсия (только первые действия, накопленная сумма)\n",
    "    \"\"\"\n",
    "    ret_kinds = ['retention']\n",
    "    cr_kinds = ['conversion', 'cr']\n",
    "\n",
    "    if (\n",
    "        kind in ret_kinds\n",
    "        and 'payer' in events.columns\n",
    "        and not 'payer' in dimensions\n",
    "    ):\n",
    "        dimensions = ['payer'] + dimensions\n",
    "\n",
    "    print('Признаки для анализа:')\n",
    "    print(dimensions)\n",
    "    # сколько пользователей совершили действия в каждый лайфтайм\n",
    "    result = events.pivot_table(\n",
    "        index=dimensions,\n",
    "        columns='lifetime',\n",
    "        values='user_id',\n",
    "        aggfunc='nunique',\n",
    "    )\n",
    "\n",
    "    if kind in cr_kinds:\n",
    "        result = result.cumsum(axis=1)\n",
    "\n",
    "    # извлекаем размеры когорт, теперь их нет в сводке\n",
    "    cohort_sizes = result.pop(0)\n",
    "    \n",
    "    # делим количество действовавших пользователей в каждый лайфтайм\n",
    "    # на размеры когорт - а когорты сформированы в лайфтайме 0!    \n",
    "    return result.div(cohort_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0618b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_rates = get_rates(attributed_events, dimensions=['date'])\n",
    "\n",
    "retention_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7442ea",
   "metadata": {},
   "source": [
    "### Churn Rate\n",
    "\n",
    "Churn Rate (коэффициент \"оттока\") - это доля тех из когорты, кто не повторил действие в следующем периоде. Доля тех, кто перестал пользоваться услугами. Доля \"ушедших\" пользователей.\n",
    "\n",
    "    Churn Rate = 1 - (current retention / previous retention)\n",
    "\n",
    "Отличается от Retention Rate тем, что Retention Rate - это отношение результата лайфтайма к результату нулевого лайфтайма, а Churn Rate - к результату предыдущего лайфтайма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba04fd",
   "metadata": {},
   "source": [
    "### Учёт момента и горизонта анализа\n",
    "\n",
    "#### Алгоритм\n",
    "\n",
    "**Момент анализа данных** - это момент времени, который нужно отобразить в результатах анализа. Что в этот момент происходило? Как всё выглядело?\n",
    "\n",
    "**Горизонт анализа данных** - максимальный лайфтайм, который мы включаем в анализ.\n",
    "\n",
    "Эти ограничения вносятся, чтобы внимание аналитика сосредоточилось на вещах, которые заведомо сопоставимы. Одинаковые лайфтаймы чтобы были в каждой когорте.\n",
    "\n",
    "Вот пример того, как умело ограничить данные, чтобы потом получить разумный результат: подсчёт среднего удержания за неделю. Естественно, берём только те когорты, которые прожили не меньше недели. Таких только две, а не все.\n",
    "\n",
    "![Как ограничивают таблицу результатов](https://pictures.s3.yandex.net/resources/Churn_Rate_4_1620471412.png)\n",
    "\n",
    "Чтобы учесть момент и горизонт анализа, нужно:\n",
    "\n",
    "- Задать момент и горизонт анализа.\n",
    "- Рассчитать самую позднюю подходящую дату привлечения пользователей.\n",
    "- Выбрать пользователей, пришедших не позже подходящей даты.\n",
    "- Выбрать события с лайфтаймом меньше (**?**) чем горизонт анализа.\n",
    "\n",
    "**?** Вопрос: почему именно \"меньше\" а не \"не больше\"? Ведь если мы хотим знать, как поступают люди через 7 дней, то нам нужно знать, что они делают на 8-ый день. То есть, через 7 дней. То есть, включая лайфтайм, который равен горизонту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9021283",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 6\n",
    "observation_date = datetime.date(2019, 5, 13)\n",
    "\n",
    "if profiles is None:\n",
    "    # создаём профили пользователей, используя записи об их посещениях\n",
    "    profiles = get_profiles(sessions, event_dt='session_start')\n",
    "\n",
    "if not observation_date:\n",
    "    observation_date = sessions['session_start'].dt.date.max()\n",
    "\n",
    "# Последний приемлимый период - это дата наблюдения.\n",
    "# Исходя из того, что за эту дату есть полные данные,\n",
    "# это не должна быть сегодняшняя дата -\n",
    "# данные за сегодня не полны, день не кончился.\n",
    "# По умолчанию, последний приемлемый период - \"день наблюдения\".\n",
    "last_suitable_acquisition_date = observation_date\n",
    "# Но если задан горизонт наблюдений,\n",
    "if horizon:\n",
    "    # то последний приемлемый период - тот, который настал на\n",
    "    # {horizon} периодов перед {observation_date}.\n",
    "    last_suitable_acquisition_date -= datetime.timedelta(days=horizon - 1)\n",
    "\n",
    "# исключаем профили, которые слишком молоды,\n",
    "# чтобы прожить нужное количество периодов\n",
    "# \"у них максимальный лайфтайм меньше чем горизонт анализа\"\n",
    "suitable_profiles = profiles.query('date <= @last_suitable_acquisition_date')\n",
    "\n",
    "# дополняем данные только теми, которые в нужных профилях\n",
    "attributed_events = get_attributed_events(sessions, profile_source=suitable_profiles, event_dt='session_start')\n",
    "\n",
    "# по умолчанию считаем, что любые лайфтаймы нас устроят\n",
    "suitable_events = attributed_events\n",
    "# но если указан горизонт анализа - то...\n",
    "if horizon:\n",
    "    # оставляем только записи с лайфтаймами,\n",
    "    # которые меньше чем горизонт анализа\n",
    "    suitable_events = attributed_events.query('lifetime < @horizon')\n",
    "\n",
    "get_rates(suitable_events, dimensions=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76f5bb",
   "metadata": {},
   "source": [
    "#### `get_suitable_events()`\n",
    "\n",
    "- `events` — данные журнала событий (сессий/посещений, регистраций, установок, покупок...),\n",
    "- `dimensions` - список признаков, по которым разделяем на когорты (по умолчанию не заданы),\n",
    "- `observation_date` — момент анализа (по умолчанию не задан),\n",
    "- `horizon` — горизонт анализа в днях (по умолчанию не задан),\n",
    "- `profiles` — профили пользователей (по умолчанию не заданы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suitable_events(events,\n",
    "                        dimensions=[],\n",
    "                        event_dt='event_dt',\n",
    "                        observation_date=None,\n",
    "                        horizon=None,\n",
    "                        profiles=None):\n",
    "    \"\"\"Возвращает список подходящих для анализа событий.\n",
    "    \n",
    "    В списке только события пользователей,\n",
    "    проживших до горизонта анализа к моменту анализа.\n",
    "    Все события дополнены признаками пользователя\n",
    "    и готовы к подсчёту статистики об удержании пользователя.\n",
    "    \"\"\"\n",
    "    if profiles is None:\n",
    "        # создаём профили пользователей, используя записи об их посещениях\n",
    "        profiles = get_profiles(events, event_dt=event_dt)\n",
    "\n",
    "    if not observation_date:\n",
    "        observation_date = events[event_dt].dt.date.max()\n",
    "\n",
    "    # Последний приемлимый период - это дата наблюдения.\n",
    "    # Исходя из того, что за эту дату есть полные данные,\n",
    "    # это не должна быть сегодняшняя дата -\n",
    "    # данные за сегодня не полны, день не кончился.\n",
    "    # По умолчанию, последний приемлемый период - \"день наблюдения\".\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    # Но если задан горизонт наблюдений,\n",
    "    if horizon:\n",
    "        # то последний приемлемый период - тот, который настал на\n",
    "        # {horizon} периодов перед {observation_date}.\n",
    "        last_suitable_acquisition_date -= datetime.timedelta(days=horizon - 1)\n",
    "\n",
    "    # исключаем профили, которые слишком молоды,\n",
    "    # чтобы прожить нужное количество периодов\n",
    "    # \"у них максимальный лайфтайм меньше чем горизонт анализа\"\n",
    "    suitable_profiles = profiles.query('date <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # дополняем данные только теми, которые в нужных профилях\n",
    "    attributed_events = get_attributed_events(events, profile_source=suitable_profiles, event_dt=event_dt)\n",
    "\n",
    "    # по умолчанию считаем, что любые лайфтаймы нас устроят\n",
    "    suitable_events = attributed_events\n",
    "    \n",
    "    # но если указан горизонт анализа - то...\n",
    "    if horizon:\n",
    "        # оставляем только записи с лайфтаймами,\n",
    "        # которые меньше чем горизонт анализа\n",
    "        suitable_events = suitable_events.query('lifetime < @horizon')\n",
    "\n",
    "    return suitable_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749e4e8",
   "metadata": {},
   "source": [
    "#### `get_retention()`\n",
    "\n",
    "- `events` — данные журнала событий (сессий/посещений, регистраций, установок, покупок...),\n",
    "- `dimensions` - список признаков, по которым разделяем на когорты (по умолчанию не заданы),\n",
    "- `observation_date` — момент анализа (по умолчанию не задан),\n",
    "- `horizon` — горизонт анализа в днях (по умолчанию не задан),\n",
    "- `profiles` — профили пользователей (по умолчанию не заданы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retention(events, event_dt='event_dt', dimensions=[], observation_date=None, horizon=None, profiles=None):\n",
    "    \"\"\"Возвращает статистику удержания пользователей.\n",
    "    \n",
    "    Требует только журнал событий.\n",
    "    \"\"\"\n",
    "    suitable_events = get_suitable_events(\n",
    "        events=events,\n",
    "        event_dt=event_dt,\n",
    "        dimensions=dimensions,\n",
    "        observation_date=observation_date,\n",
    "        horizon=horizon,\n",
    "        profiles=profiles,\n",
    "    )\n",
    "\n",
    "    result = get_rates(suitable_events, kind='retention', dimensions=dimensions)\n",
    "    return suitable_events, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92897c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, retention = get_retention(\n",
    "    events=sessions,\n",
    "    event_dt='session_start',\n",
    "    dimensions=['date'],\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c100b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c853bd",
   "metadata": {},
   "source": [
    "### Визуализация\n",
    "\n",
    "#### `show_heatmap_table()` - тепловая карта удержания\n",
    "\n",
    "Хитмэп — отличный выбор, если вы хотите сравнить удержание нескольких когорт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap_table(retention, figsize=(15, 6)):\n",
    "    \"\"\"Показывает единую тепловую карту удержаний.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        retention,\n",
    "        annot=True,  # включаем подписи\n",
    "        fmt='.2%',  # переводим значения в проценты\n",
    "    )\n",
    "    plt.title('Тепловая карта удержания')  # название графика\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5490360",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, triangle_retention = get_retention(sessions, event_dt='session_start', dimensions=['date'])\n",
    "show_heatmap_table(triangle_retention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797f94e",
   "metadata": {},
   "source": [
    "#### Кривая удержания\n",
    "\n",
    "Кривые удержания подходят для «быстрого» сравнения показателей. Метод `plot()` строит график, на котором линии отражают значения каждого столбца датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# транспонирование (переворачивание) таблицы с помощью атрибута T:\n",
    "# столбцы становятся строками, а строки - столбцами\n",
    "test = retention.T\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da17b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это способ получить названия строк\n",
    "test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b798900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим кривые удержания\n",
    "retention.T.plot(\n",
    "    grid=True,\n",
    "    # отметки на оси X — названия колонок retention, то есть - номера лайфтаймов\n",
    "    xticks=list(retention.columns),\n",
    "    figsize=(15, 5),\n",
    ")\n",
    "plt.xlabel('Лайфтайм')  # название оси X\n",
    "plt.title('Кривые удержания по дням привлечения')  # название графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a8034",
   "metadata": {},
   "source": [
    "#### Кривые истории изменения удержаний\n",
    "\n",
    "Если задача — проанализировать, как менялось удержание от когорты к когорте для каждого дня «жизни» пользователей, подойдёт график истории изменений.\n",
    "\n",
    "Построить такой график проще всего — достаточно вызвать `plot()` к таблице удержания. Без всякого транспонирования.\n",
    "\n",
    "Каждая линия на этом графике показывает, как менялось удержание пользователей на определённый лайфтайм. Например, синяя линия сверху отражает изменения в удержании второго дня или первого лайфтайма (лайфтайм 1 - прошёл один полный день, идёт второй), а нижняя фиолетовая — в удержании шестого дня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим графики изменений\n",
    "retention.plot(grid=True, figsize=(15, 5))\n",
    "plt.xlabel('Дата привлечения')\n",
    "plt.title('Динамика удержания пользователей')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61058ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(URL + 'profiles_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ac620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "events, retention = get_retention(\n",
    "    sessions, event_dt='session_start',\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['payer'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим тепловую карту\n",
    "retention.T.plot(grid=True, xticks=retention.columns, figsize=(15, 5))\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.title('Кривые удержания двух когорт: совершавшие покупку и не совершавшие')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a1d16",
   "metadata": {},
   "source": [
    "### Графики, которые отображают когорты с двумя-тремя признаками\n",
    "\n",
    "Удержание платящих значительно выше удержания неплатящих. Так бывает почти всегда, поэтому разбивка пользователей на платящих и неплатящих — стандартная практика. Мы дополнили `get_retention`, он учитывает разбивкуй на когорты: плательщики и лиды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79399138",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, retention = get_retention(\n",
    "    sessions, event_dt='session_start',\n",
    "    # а следующий фрейм содержит колонку `payer`\n",
    "    # если колонку или весь фрейм убрать - то разбивка\n",
    "    # на тех кто платил и кто не платил - исчезнет\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['date']\n",
    ")\n",
    "\n",
    "retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7cdbe",
   "metadata": {},
   "source": [
    "#### Тепловые карты удержания\n",
    "\n",
    "Видим, что у нас составной индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap_table(retention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea5ef7",
   "metadata": {},
   "source": [
    "Теперь каждой строке таблицы удержания соответствуют два параметра: дата и признак совершения покупки. График и подписи заметно разрослись.\n",
    "\n",
    "Разделим график надвое: построим по тепловой карте для каждой группы пользователей — платящих и неплатящих. Для этого вызовем функцию `figure()` из модуля `pyplot` библиотеки `matplotlib` и напишем цикл `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2930585",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6)) # задаём размер холста для графиков\n",
    "\n",
    "# берём порядковый номер и имя категории\n",
    "# а категорий всего две: \"платил\" и \"не платил\"\n",
    "for i, payer in enumerate(profiles['payer'].unique()):\n",
    "    sns.heatmap(\n",
    "        # из всей таблицы удержаний берём только те записи,\n",
    "        # где индекс 'payer' равен значению 'payer' из итератора\n",
    "        retention.query('payer == @payer')\n",
    "        # удаляем индекс payer - он теперь не нужен\n",
    "        .droplevel('payer'),\n",
    "        # добавляем подписи значений\n",
    "        annot=True,\n",
    "        # переводим значения в проценты\n",
    "        fmt='.2%',\n",
    "        # строим каждый график в своей ячейке\n",
    "        # (number_of_rows, number_of_cols, index)\n",
    "        # index starts at 1 in the upper left corner and increases to the right.\n",
    "        # index can also be a two-tuple specifying the (first, last) indices\n",
    "        # (1-based, and including last) of the subplot,\n",
    "        # e.g., fig.add_subplot(3, 1, (1, 2)) makes a subplot\n",
    "        # that spans the upper 2/3 of the figure.\n",
    "        ax=plt.subplot(1, 2, i + 1),\n",
    "    )\n",
    "    # задаём названия графиков с учётом значения payer\n",
    "    plt.title('Тепловая карта удержания для payer = {}'.format(payer))\n",
    "\n",
    "plt.tight_layout()  # «подгоняем» размер графиков, чтобы уместились подписи\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c730c0",
   "metadata": {},
   "source": [
    "В программе для построения двух хитмэпов мы передали функции `subplot()` аргументы `1`, `2` и `i + 1`: в таблице графиков одна строка и два столбца. \n",
    "\n",
    "```python\n",
    "        ax=plt.subplot(1, 2, i + 1)\n",
    "```\n",
    "\n",
    "Переменная `i` принимает значения `0` и `1`, а нумерация ячеек в таблице графиков начинается с единицы, поэтому значение `i` увеличиваем на один. Так первый график окажется в первой ячейке, а второй — во второй."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bca01e",
   "metadata": {},
   "source": [
    "#### Кривые удержания\n",
    "\n",
    "Проанализируем удержание с разбивкой когорт не по дате, а по другому параметру — устройству, с которого пользователи впервые зашли на сайт. Эта информация сохранена в столбце `device` — добавим его в параметр `dimensions`. Горизонт и момент анализа данных остаются прежними. Вызовем функцию `get_retention()` и построим хитмэп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6102a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, retention = get_retention(\n",
    "    sessions,\n",
    "    event_dt='session_start',\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['device'],\n",
    ")\n",
    "\n",
    "retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b681add",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(retention, annot=True, fmt='.2%')\n",
    "plt.title('Тепловая карта удержания')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49217f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i, payer in enumerate(profiles['payer'].unique()):\n",
    "    retention.query('payer == @payer').droplevel('payer').T.plot(\n",
    "        grid=True,\n",
    "        xticks=retention.columns,\n",
    "        ax=plt.subplot(1, 2, i + 1),\n",
    "    )\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Кривые удержания для payer = {}'.format(payer))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa5d0c",
   "metadata": {},
   "source": [
    "По правому графику с кривыми удержания неплатящих пользователей сложно определить, пользователи каких устройств удерживаются хоть сколько-то лучше.\n",
    "\n",
    "#### Кривые истории изменений удержания\n",
    "\n",
    "Избежать слияния линий позволит третий изученный вами способ визуализации — график истории изменений. На таком графике каждая линия соответствует определённому лайфтайму, а по горизонтальной оси отмечены даты привлечения пользователей. \n",
    "\n",
    "Однако построить его теперь непросто: после добавления параметра `dimensions` даты привлечения пользователей пропали из таблицы удержания.\n",
    "\n",
    "История изменений удержания - это по сути анализ когорт, у которых главный признак - период, в который когорта пришла. Даты становятся обязательным признаком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, retention = get_retention(\n",
    "    sessions, event_dt='session_start',\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['device', 'date'],\n",
    ")\n",
    "\n",
    "retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28284f",
   "metadata": {},
   "source": [
    "Получаем таблицу удержания, сгруппированную по трём признакам:\n",
    "\n",
    "- Совершение покупок. Столбец `payer`, значение `True` или `False`.\n",
    "- Устройство, с которого пользователь просматривает сайт. Столбец `device`, значения `Android`, `Mac`, `PC` или `iPhone`.\n",
    "- Дата привлечения пользователей. Столбец `dt` с датами от 1 до 8 мая 2019 года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08151a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# холст для графиков будет такого размера\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# на холст графики станут в столько рядов,\n",
    "# сколько вариантов в 'payer'\n",
    "nrows = len(profiles['payer'].unique())\n",
    "# и столько столбцов, сколько вариантов в 'payer'\n",
    "ncols = len(profiles['first_device'].unique())\n",
    "\n",
    "# наружний цикл - перебор строк, рядов\n",
    "for i, payer in enumerate(profiles['payer'].unique()):\n",
    "    # внутренний цикл - перебо столбцов, позиций в ряду\n",
    "    for j, device in enumerate(profiles['first_device'].unique()):\n",
    "        (\n",
    "            # оставляем записи, в которых нужный статус плательщика и нужное устройство\n",
    "            retention.query('payer == @payer and device == @device')\n",
    "            .droplevel(['payer', 'device'])\n",
    "            .plot(\n",
    "                grid=True,\n",
    "                # количество рядов и ячеек в ряду - берутся из констант, заданных до цикла\n",
    "                # номер ячейки, куда запишем диаграмму - вычисляется\n",
    "                # на основе порядковых номеров итераций циклов\n",
    "                ax=plt.subplot(nrows, ncols, i * ncols + j + 1),\n",
    "                rot=30,\n",
    "            )\n",
    "        )\n",
    "        plt.xlabel('Дата привлечения')\n",
    "        plt.title('Удержание для payer = {} на {}'.format(payer, device))\n",
    "\n",
    "# Adjust the padding between and around subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d3bce",
   "metadata": {},
   "source": [
    "#### Неудачные кривые удержания - когда признаков больше двух\n",
    "\n",
    "В принципе, это же можно увидеть и на обычных линейных графиках удержания. Построим их, запустив код, который мы использовали для одного дополнительного признака, но теперь  - с двумя дополнительными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756bad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))  # задаём размер сетки\n",
    "\n",
    "for i, payer in enumerate(profiles['payer'].unique()):\n",
    "    retention.query('payer == @payer').droplevel('payer').T.plot(\n",
    "        grid=True,\n",
    "        xticks=retention.columns,\n",
    "        ax=plt.subplot(1, 2, i + 1), # задаём расположение графиков\n",
    "    )\n",
    "    plt.xlabel('Лайфтайм')\n",
    "    plt.title('Кривые удержания для payer = {}'.format(payer))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924c156",
   "metadata": {},
   "source": [
    "Итак, каждая линия - когорта по трём признакам. Один признак - платежи, по ним когорты распределены вправо и влево. В целом, было бы удобнее распределить их так, как в примере с историей удержания - по горизонтали устройста, по вертикали - наличие платежей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9367525",
   "metadata": {},
   "source": [
    "#### Удачные графики удержания, если много двух признаков\n",
    "\n",
    "Чтобы построить кривые удержания с разбивкой по совершению покупок и устройствам, параметру `dimensions` при вызове функции `get_retention()` нужно передать только столбец `device`. Перегруппировать текущую таблицу уже не выйдет: для группировки нужны сырые данные, а не готовые коэффициенты.\n",
    "\n",
    "На практике аналитик почти всегда хочет видеть и кривые удержания, и графики истории изменений. Чтобы иметь доступ и к тому, и к другому виду графиков, можно вызвать `get_retention()` дважды — с разным набором столбцов в параметре `dimensions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17325900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# один вызов для построения кривых удержания\n",
    "events, retention = get_retention(\n",
    "    sessions, event_dt='session_start',\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['device'], \n",
    ")\n",
    "\n",
    "# и другой — для построения графиков динамики удержания\n",
    "events, retention_history = get_retention(\n",
    "    sessions, event_dt='session_start',\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['device', 'date'], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398a672",
   "metadata": {},
   "source": [
    "Однако это не лучший вариант. \n",
    "\n",
    "Во-первых, мы дважды создаём один и тот же датафрейм с сырыми данными `events`. Это замедляет работу программы. \n",
    "\n",
    "Во-вторых, за одно исследование аналитик обычно рассчитывает удержание не один, а множество раз — с разбивкой когорт по совершенно разным признакам. Каждый раз вызывать одну и ту же функцию дважды неудобно.\n",
    "\n",
    "Гораздо эффективнее за один вызов `get_retention()` получать сразу три таблицы:\n",
    "\n",
    "- события с атрибутами,\n",
    "- удержание,\n",
    "- динамика удержания.\n",
    "\n",
    "Таблица динамики удержания отличается от простой таблицы удержания обязательной группировкой по дополнительному признаку — дате привлечения пользователей. А вот таблица удержания может не содержать этого признака. Добавим в тело функции `get_retention()` создание таблицы `retention_in_time`, которая будет сгруппирована по всем признакам из `dimensions`, а также столбцу `date`.\n",
    "\n",
    "#### `get_retention_hist()` (using `date` in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0bd6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retention_hist(events, event_dt='event_dt',\n",
    "                       dimensions=[],\n",
    "                       observation_date=None,\n",
    "                       horizon=None,\n",
    "                       profiles=None):\n",
    "    \"\"\"Возвращает статистику удержания, дополняя разбивкой по дням.\n",
    "    \n",
    "    Это можно использовать, чтобы дополнить графики\n",
    "    графиками истории удержания.\n",
    "    \"\"\"\n",
    "    # получаем подготовленные данные о событиях и основную статистику\n",
    "    suitable_events, retention = get_retention(\n",
    "        events=events,\n",
    "        event_dt=event_dt,\n",
    "        dimensions=dimensions,\n",
    "        observation_date=observation_date,\n",
    "        horizon=horizon,\n",
    "        profiles=profiles,\n",
    "    )\n",
    "    \n",
    "    # готовим и историю удержания\n",
    "    # по умолчанию история удержания пуста\n",
    "    retention_in_time = None\n",
    "    # но если есть поле с датами, то...\n",
    "    if 'date' in suitable_events:\n",
    "        # история удержания - это таблица удержания с ещё одним признаком - датой\n",
    "        retention_in_time = get_rates(\n",
    "            suitable_events,\n",
    "            dimensions=(dimensions + ['date'])\n",
    "        )\n",
    "\n",
    "    return suitable_events, retention, retention_in_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8d984",
   "metadata": {},
   "source": [
    "#### Автопостроение холстов с графиками\n",
    "\n",
    "##### `show_retention_line_plot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_retention_line_plot(retention, figsize=(20, 8)):\n",
    "    \"\"\"Показывает графики удержания. \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # retention.droplevel(-1).index.names:\n",
    "    # retention.index.names[0]\n",
    "    \n",
    "    # указываем, какой признак \"распределим\" по горизонтальным графикам\n",
    "    dimension = 'payer'\n",
    "    # и какие у него уникальные варианты\n",
    "    unique_values = retention.index.get_level_values(dimension).unique()\n",
    "    # зафиксируем, сколько графиков будет в одном ряду\n",
    "    ncols = len(unique_values)\n",
    "\n",
    "    for i, value in enumerate(unique_values):\n",
    "        (\n",
    "            # оставляем для графика только те данные,\n",
    "            # которые соответствуют нужному значению\n",
    "            retention.query('payer == @value')\n",
    "            # выкидываем не нужный в этой пикче уровень\n",
    "            .droplevel(dimension)\n",
    "            # транспонируем и рисуем график\n",
    "            .T.plot(\n",
    "                grid=True,\n",
    "                xticks=list(retention.columns),\n",
    "                ax=plt.subplot(1, ncols, i + 1),\n",
    "            )\n",
    "        )\n",
    "        plt.xlabel('Лайфтайм')\n",
    "        plt.title('Кривые удержания для {} = {}'.format(dimension, value))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6804e5e",
   "metadata": {},
   "source": [
    "##### `get_retention_hist_plot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_retention_hist_plot(retention_history, figsize=(20, 8)):\n",
    "    \"\"\"Показывает графики истории удержания.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    row_dimension = 'payer'\n",
    "    col_dimension = 'device'\n",
    "    \n",
    "    unique_row_values = retention_history.index.get_level_values(row_dimension).unique()\n",
    "    unique_col_values = retention_history.index.get_level_values(col_dimension).unique()\n",
    "\n",
    "    nrows = len(unique_row_values)\n",
    "    ncols = len(unique_col_values)\n",
    "\n",
    "    for i, row_value in enumerate(unique_row_values):\n",
    "        for j, col_value in enumerate(unique_col_values):\n",
    "            (\n",
    "                retention_history.query('payer == @row_value and device == @col_value')\n",
    "                .droplevel([row_dimension, col_dimension])\n",
    "                .plot(\n",
    "                    grid=True,\n",
    "                    rot=30,\n",
    "                    ax=plt.subplot(nrows, ncols, i * ncols + j + 1),\n",
    "                )\n",
    "            )\n",
    "            plt.xlabel('Дата привлечения')\n",
    "            plt.title('Удержание для {} = {} на {}'.format(row_dimension, row_value, col_value))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0382f5",
   "metadata": {},
   "source": [
    "##### `show_retention()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19066d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_retention(*args, **kwargs):\n",
    "    \"\"\"Даёт полный обзор удержания.\n",
    "    \"\"\"\n",
    "    events, retention, retention_history = get_retention_hist(*args, **kwargs)\n",
    "    display(events)\n",
    "    display(retention)\n",
    "    display(retention_history)\n",
    "    show_heatmap_table(retention)\n",
    "    show_retention_line_plot(retention)\n",
    "    show_retention_hist_plot(retention_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8480d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_retention(\n",
    "    sessions, event_dt='session_start',\n",
    "    profiles=profiles,\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=6,\n",
    "    dimensions=['device'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6de3a",
   "metadata": {},
   "source": [
    "#### Conversion Rate в когортном анализе\n",
    "\n",
    "Итак, конверсия - это доля людей, перешедших в новый этап, из состояния в состояние. Коэффициент конверсии когорты - это доля когорты, совершившей действие.\n",
    "\n",
    "Чаще всего речь об оплате: из \"неплатящих\" в платящие. Когда растёт доля платящих - обычно это хорошо.\n",
    "\n",
    "![Число плательщиков в выбранной когорте пользователей](https://pictures.s3.yandex.net/resources/Conversion_Rate_2_1620486051.png)\n",
    "\n",
    "Смотрим внимательно: в таблице - число _первых_ покупок в лайфтайм в когорте. Ниже - общее число число _первых_ покупок в этой когорте, с начала наблюдений до завершения текущего лайфтайма.\n",
    "\n",
    "Convertion Rate = накопленное число \"конвертировавшихся\" из когорты / размер когорты.\n",
    "\n",
    "![Конверсия в когорте](https://pictures.s3.yandex.net/resources/Conversion_Rate_4_1620486122.png)\n",
    "\n",
    "Тут тоже важны _горизонт наблюдения_ и _дата наблюдения_.\n",
    "\n",
    "![Треугольная таблица](https://pictures.s3.yandex.net/resources/Conversion_Rate_5_1620486401.png)\n",
    "\n",
    "![Её обработка](https://pictures.s3.yandex.net/resources/Conversion_Rate_6_1620486529.png)\n",
    "\n",
    "Расчёт конверсии при когортном анализе очень похож на расчёт коэффициентов удержания и оттока. Отличие — в _исходных данных_. Если для удержания и оттока важно _количество активных пользователей_ в каждый из дней «жизни», то для конверсии — _количество первых покупок_.\n",
    "\n",
    "Как рассчитать Conversion Rate по когортам:\n",
    "1. Получить пользовательские профили и данные о покупках.\n",
    "2. Найти дату и время первой покупки для каждого пользователя.\n",
    "3. Добавить данные о покупках в профили.\n",
    "4. Рассчитать лайфтайм пользователя для каждой покупки.\n",
    "5. Построить таблицу конверсии - сводную таблицу, в которой:\n",
    "  - названия строк — это даты первого посещения пользователей,\n",
    "  - названия столбцов — лайфтайм,\n",
    "  - а значения в «ячейках» — количество уникальных идентификаторов пользователей.\n",
    "6. Посчитать сумму с накоплением для каждой строки таблицы конверсии.\n",
    "7. Вычислить размеры когорт и занести результаты в отдельную таблицу.\n",
    "8. Разделить каждую «ячейку» таблицы конверсии на соответствующий размер когорты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7689b51",
   "metadata": {},
   "source": [
    "Если взглянуть, то понятно, что данные для конверсии (платежи) устроены так же, как данные для удержания (посещения). И профили достраиваются так же - поиском первых по времени событий. И прибавляются к событиям профили так же. Итого, шаги 1...4 делаются так: к платежам применить тот же `get_suitable_events()`.\n",
    "\n",
    "5 и 6 шаги: способ группировки и aggfunc() при вычислениях конверсии - другой. Его и напишем. Может, потом оформить `get_retention()` и `get_conversion()` как единый декоратор над `get_retention/convertion_rates()`.\n",
    "\n",
    "7 и 8 шаги: по сути как в удержании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ca318",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e9f2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# выбираем покупки\n",
    "suitable_purchases = get_suitable_events(\n",
    "    orders,\n",
    "    # добавляем их в профили, созданные на основе сессий\n",
    "    profiles=get_profiles(\n",
    "        # делаем так, чтобы время события у сессий и покупок\n",
    "        # было под одинаковыми названиями - так их проще сравнить\n",
    "        sessions.rename(columns={'session_start': 'event_dt'})\n",
    "    )\n",
    ")\n",
    "\n",
    "suitable_purchases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf84f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rates(suitable_purchases, kind='conversion', dimensions=['first_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d40fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = ['first_region']\n",
    "\n",
    "# сколько пользователей совершили действия в каждый лайфтайм\n",
    "result = suitable_purchases.pivot_table(\n",
    "    index=dimensions,\n",
    "    columns='lifetime',\n",
    "    values='user_id',\n",
    "    aggfunc='nunique',\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39172275",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.cumsum(axis=1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5be338",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_sizes = suitable_purchases.groupby('first_region').agg({'event_dt': 'count'})\n",
    "cohort_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ee321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.div(cohort_sizes['event_dt'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c84890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversion(\n",
    "    profiles,\n",
    "    purchases,  # заменили sessions\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # Шаг 1. Получить пользовательские профили и данные о покупках\n",
    "    # передаём их в качестве аргументов profiles и purchases\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - datetime.timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('date <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # Шаг 2. Найти дату и время первой покупки для каждого пользователя\n",
    "    first_purchases = (\n",
    "        purchases.sort_values(by=['user_id', 'event_dt'])\n",
    "        .groupby('user_id')\n",
    "        .agg({'event_dt': 'first'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Шаг 3. Добавить данные о покупках в профили\n",
    "    result_raw = result_raw.merge(\n",
    "        first_purchases[['user_id', 'event_dt']], on='user_id', how='left'\n",
    "    )\n",
    "\n",
    "    # Шаг 4. Рассчитать лайфтайм для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_session_start']\n",
    "    ).dt.days\n",
    "\n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция для группировки таблицы по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "\n",
    "        # Шаг 5. Построить таблицу конверсии\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "\n",
    "        # Шаг 6. Посчитать сумму с накоплением для каждой строки\n",
    "        result = result.fillna(0).cumsum(axis = 1)\n",
    "\n",
    "        # Шаг 7. Вычислить размеры когорт\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "\n",
    "        # Шаг 8. Объединить таблицы размеров когорт и конверсии\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "\n",
    "        # Шаг 9. Разделить каждую «ячейку» в строке на размер когорты\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "\n",
    "        # исключаем все лайфтаймы, превышающие горизонт анализа\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        # восстанавливаем размеры когорт\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # получаем таблицу конверсии\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # для таблицы динамики конверсии убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions: \n",
    "        dimensions = []\n",
    "\n",
    "    # получаем таблицу динамики конверсии\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['date'], horizon_days\n",
    "    )\n",
    "\n",
    "    # возвращаем обе таблицы и сырые данные\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd96637",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a988da",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947c029",
   "metadata": {},
   "source": [
    "В столбце `event_dt` датафрейма `orders` хранятся дата и время совершения покупки — как и предусмотрено в коде функции `get_conversion()`.\n",
    "\n",
    "Рассчитаем конверсию с разбивкой по регионам, передав `get_conversion()` фреймы `profiles` и `orders`, а также столбец `region` в качестве параметра `dimensions`, и построим тепловую карту по таблице конверсии. Момент и горизонт анализа данных остаются прежними — 13 мая 2019 года и 6 дней соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2721adf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conversion_raw, conversion, conversion_history = get_conversion(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 6, dimensions=['first_region']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.heatmap(conversion.drop(columns=['cohort_size']), annot=True, fmt='.2%')\n",
    "plt.title('Тепловая карта конверсии по странам')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082bb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 5)) # задаём размер «подложки»\n",
    "\n",
    "# исключаем размеры когорт\n",
    "# конверсии первого дня различаются, их удалять не нужно\n",
    "report = conversion.drop(columns = ['cohort_size'])\n",
    "\n",
    "sns.heatmap(\n",
    "    report, annot=True, fmt='.2%', ax=plt.subplot(1, 2, 1)\n",
    ")  # в первой ячейке таблицы графиков строим тепловую карту\n",
    "plt.title('Тепловая карта конверсии по странам')\n",
    "\n",
    "report.T.plot(\n",
    "    grid=True, xticks=list(report.columns.values), ax=plt.subplot(1, 2, 2)\n",
    ")  # во второй — кривые конверсии\n",
    "plt.title('Кривые конверсии по странам')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083aa9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем конверсию без параметра dimensions\n",
    "conversion_raw, conversion, conversion_history = get_conversion(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 6\n",
    ")\n",
    "\n",
    "# строим хитмэп по таблице конверсии\n",
    "sns.heatmap(conversion.drop(columns=['cohort_size']), annot=True, fmt='.2%')\n",
    "plt.title('Тепловая карта конверсии без разбивки')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bce9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, conversion, conversion_hist = get_conversion(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 6, dimensions=['first_region']\n",
    ")\n",
    "conversion_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d0ae7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "report = conversion.drop(columns=['cohort_size'])\n",
    "report.T.plot(\n",
    "    grid=True, xticks=list(report.columns), ax=plt.subplot(1, 2, 1)\n",
    ")\n",
    "plt.title('Конверсия первых шести дней с разбивкой по странам')\n",
    "\n",
    "# для графика истории изменений преобразуем таблицу динамики конверсии\n",
    "report = (\n",
    "    conversion_hist[1]\n",
    "    .reset_index()\n",
    "    .pivot_table(index='date', columns='first_region', values=1, aggfunc='mean')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "report.plot(\n",
    "    grid=True, ax=plt.subplot(1, 2, 2)\n",
    ")\n",
    "plt.title('Динамика конверсии второго дня с разбивкой по странам')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6fde1",
   "metadata": {},
   "source": [
    "## Юнит-экономика\n",
    "\n",
    "Сколько зарабатывает бизнес с одного объекта.\n",
    "\n",
    "Описывает, как:\n",
    "- рассчитывать экономику одной продажи;\n",
    "- определять, при каком объёме продаж бизнес выйдет в плюс;\n",
    "- выбирать подходящую модель оплаты рекламы;\n",
    "- считать пожизненную ценность, стоимость привлечения и окупаемость клиентов;\n",
    "- быстро визуализировать основные метрики.\n",
    "\n",
    "### С покупателя\n",
    "\n",
    "Инвестиции в маркетинг строятся по принципу: «Вкладываем деньги в рекламу и получаем новые заказы. Если прибыль с заказа выше, чем затраты на его получение, значит, всё хорошо». Но на самом деле компании привлекают не заказы — привлекают покупателей, которые заказывают.\n",
    "\n",
    "Главный принцип успешных инвестиций - полученный доход должен превысить затраты.\n",
    "\n",
    "Чтобы включить в анализ повторные покупки, считают экономику одного покупателя. Три самые важные метрики в этом методе — LTV, CAC и ROI.\n",
    "\n",
    "Для всех расчётов в когорте по-прежнему действуют правила. По-прежнему нужно выбирать когорты не моложе чем нужно, и выбирать лайфтаймы не больше чем нужно.\n",
    "\n",
    "### LTV Lifetime Value (ARPU Average Revenue Per User)\n",
    "\n",
    "Чем больше клиент дал денег - тем он лучше для нас.\n",
    "\n",
    "Это общая сумма денег, которую один клиент в среднем приносит компании со всех своих покупок. В теории эта метрика включает все прошлые, нынешние и будущие покупки пользователя. На практике чаще анализируют LTV за определённый срок — первые 1, 3, 7 и 14 дней после регистрации. Другое название - ARPU - Average revenue per user.\n",
    "\n",
    "    LTV = накопленная выручка с людей когорты / объём когорты\n",
    "\n",
    "_Выручка от пользователей в каждый из лайфтаймов._\n",
    "![Выручка](https://pictures.s3.yandex.net/resources/LTV_2_1643809761.png)\n",
    "\n",
    "_Сводка по накопленной выручке в каждой когорте._\n",
    "![Сводка](https://pictures.s3.yandex.net/resources/LTV_3_1620494437.png)\n",
    "\n",
    "_Сводка по LTV в каждой когорте._\n",
    "![Сводка LTV](https://pictures.s3.yandex.net/resources/LTV_4_1620494466.png)\n",
    "\n",
    "\n",
    "#### ARPPU Average Revenue Per Paying User\n",
    "\n",
    "    ARPPU = Выручка с когорты / количество тех из когорты, кто сделал хоть одну покупку.\n",
    "\n",
    "Иногда используются вместо LTV. За счёт исключения неплатящих пользователей ARPPU часто более показателен, чем ARPU, но считать его труднее: во-первых, число платящих в когорте со временем растёт, а во-вторых, для расчёта требуются данные о том, делал ли покупку конкретный пользователь.\n",
    "\n",
    "Выбор между ARPU и ARPPU **_отчасти__ зависит от способа оплаты рекламы**, которым пользуется компания. Самые распространённые — СPM, СPC, CPL/CPI и CPA.\n",
    "\n",
    "**ARPU:**\n",
    "- **CPM cost per mille** - сложно учитывать, потому что не каждый просмотр вызывает переход.\n",
    "- **CPC cost per click** - оплаченный пользователь зашёл на сайт, ему можно закрепить куки, которые потом позволят понять, кто он, из какой когорты. Правда, куки не точны, теряются и блокируются/уничтожаются.\n",
    "**ARPPU:**\n",
    "- **CPL cost per lead, CPI cost per install** - оплата за пользователя, оставившего контакты или установившего прилогу. Идентификатор - логин / почта / телефон / рекламный ID устройства. Предпочитают её, а не CPA.\n",
    "- **CPA cost per action** - оплата за действие (покупку, подписку, голос или ещё что то). Внедрять сложно, но подсчёт эффективности самый ясный.\n",
    "\n",
    "\n",
    "#### Алгоритм\n",
    "- Получить пользовательские профили и данные о покупках.\n",
    "- Добавить данные о покупках в профили.\n",
    "- Рассчитать лайфтайм пользователя для каждой покупки.\n",
    "- Построить таблицу выручки. То есть сводную таблицу, в которой названия строк — это даты первого посещения пользователей, названия столбцов — лайфтайм, а значения в «ячейках» — выручка.\n",
    "- Посчитать сумму с накоплением для каждой строки таблицы выручки.\n",
    "- Вычислить размеры когорт и занести результаты в отдельную таблицу.\n",
    "- Объединить таблицы размеров когорт и выручки.\n",
    "- Посчитать LTV: разделить каждую «ячейку» таблицы выручки на соответствующий размер когорты.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc860bc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profiles = profiles.rename(columns={'first_session_start': 'first_ts'})\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde05f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltv(\n",
    "    profiles,  # Шаг 1. Получить профили и данные о покупках\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - datetime.timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('date <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # Шаг 2. Добавить данные о покупках в профили\n",
    "\n",
    "    result_raw = result_raw.merge(\n",
    "        # добавляем в профили время совершения покупок и выручку\n",
    "        purchases[['user_id', 'event_dt', 'revenue']],\n",
    "        on='user_id',\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "    # Шаг 3. Рассчитать лайфтайм пользователя для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция для группировки таблицы по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "\n",
    "        # Шаг 3. Построить таблицу выручки\n",
    "        # строим «треугольную» таблицу\n",
    "        result = df.pivot_table(\n",
    "            index=dims,\n",
    "            columns='lifetime',\n",
    "            values='revenue',  # в ячейках — выручка за каждый лайфтайм\n",
    "            aggfunc='sum',\n",
    "        )\n",
    "\n",
    "        # Шаг 4. Посчитать сумму выручки с накоплением\n",
    "        result = result.fillna(0).cumsum(axis=1)\n",
    "\n",
    "        # Шаг 5. Вычислить размеры когорт\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "\n",
    "        # Шаг 6. Объединить размеры когорт и таблицу выручки\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "\n",
    "        # Шаг 7. Посчитать LTV\n",
    "        # делим каждую «ячейку» в строке на размер когорты\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        # исключаем все лайфтаймы, превышающие горизонт анализа\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        # восстанавливаем размеры когорт\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # получаем таблицу LTV\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # для таблицы динамики LTV убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions:\n",
    "        dimensions = []\n",
    "    # получаем таблицу динамики LTV\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['date'], horizon_days\n",
    "    )\n",
    "\n",
    "    # возвращаем обе таблицы LTV и сырые данные\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b8ddc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ltv_raw, ltv, ltv_history = get_ltv(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 7\n",
    ")\n",
    "\n",
    "sns.heatmap(ltv.drop(columns=['cohort_size']), annot=True, fmt='.2f')\n",
    "plt.title('Тепловая карта LTV без разбивки')\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a682729",
   "metadata": {},
   "source": [
    "LTV за неделю после привлечения составил 0,81 доллара на пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5297fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим кривые LTV\n",
    "\n",
    "ltv_raw, ltv, ltv_history = get_ltv(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 7, dimensions=['first_region']\n",
    ")\n",
    "\n",
    "report = ltv.drop(columns=['cohort_size'])\n",
    "report.T.plot(grid=True, figsize=(10, 5), xticks=list(report.columns))\n",
    "plt.title('LTV с разбивкой по странам')\n",
    "plt.ylabel('LTV, $')\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa043f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график истории изменений LTV\n",
    "\n",
    "ltv_raw, ltv, ltv_history = get_ltv(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 7\n",
    ")\n",
    "\n",
    "report = ltv_history[[0, 4, 6]]\n",
    "report.plot(grid=True, figsize=(10, 5))\n",
    "\n",
    "plt.title('Динамика LTV 1-го, 5-го и 7-го дней жизни')\n",
    "plt.ylabel('LTV, $')\n",
    "plt.xlabel('Даты привлечения пользователей')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, retention, retention_hist = get_retention_hist(\n",
    "    sessions,\n",
    "    profiles=profiles.rename(columns={'first_ts': 'first_session_start'}),\n",
    "    observation_date=datetime.date(2019, 5, 13),\n",
    "    horizon=7,\n",
    "    event_dt='session_start',\n",
    ")\n",
    "\n",
    "report = retention_hist.query('payer == True').droplevel('payer')[[4, 6]]\n",
    "report.plot(grid=True, figsize=(10, 5))\n",
    "plt.title('Динамика удержания 5-го и 7-го дней жизни')\n",
    "plt.ylabel('Удержание')\n",
    "plt.xlabel('Дата привлечения пользователей')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d40549",
   "metadata": {},
   "source": [
    "Получается, в когортах с 3 по 5 мая - удержание маленькое. LTV нулевого дня в тех когортах велико, а вот пятого и седьмого дня - маленькие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2279b6",
   "metadata": {},
   "source": [
    "### CAC Customer Acquisition Cost\n",
    "\n",
    "Это стоимость привлечения одного клиента. Сумма денег, в которую компании обходится каждый новый клиент.\n",
    "\n",
    "CAC = Расходы на рекламу (инвестиции в маркетинг), привлёкшую когорту / размер когорты\n",
    "\n",
    "Считается, что реклама (холодная) нужна только для формирования когорты, не для её удержания. Поэтому принято, что CAC окончательно рассчитывается в момент, как только когорта сформирована (закончился лайфтайм 0), и далее CAC этой когорты не меняется. Это **константа** для когорты.\n",
    "\n",
    "_Сводка: LTV и дописанные перед ними расходы на рекламу и CAC._\n",
    "![](https://pictures.s3.yandex.net/resources/LTV_5_1620494721.png)\n",
    "_Вообще, поскольку есть полные расходы - логично будет дописать полные доходы с когорты._\n",
    "\n",
    "Можно сравнивать CAC и LTV в лоб.\n",
    "\n",
    "_График LTV по сравнению с CAC._\n",
    "![](https://pictures.s3.yandex.net/resources/graph_2_1620494745.png)\n",
    "_Когорта 1 апреля окупилась к концу второго дня существования. Когорта 2 апреля не окупилась по итогам семи дней. Судя по графику, маркетологи дорого купили трафик (в маркетинге так называют поток посетителей)._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09ca04",
   "metadata": {},
   "source": [
    "#### Алгоритм\n",
    "\n",
    "- Передать функции для создания профилей данные о тратах на рекламу.\n",
    "- Объединить данные о тратах на рекламу и новых пользователях.\n",
    "- Вычислить CAC: разделить рекламные расходы на количество новых пользователей.\n",
    "- Добавить CAC для каждой даты привлечения и источника в профили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = pd.read_csv(URL + 'ad_costs_new.csv')\n",
    "costs['date'] = pd.to_datetime(costs.pop('dt')).dt.date\n",
    "costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.rename(columns={'first_channel': 'channel'})\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs.merge(\n",
    "    profiles.groupby(['date', 'channel']).agg({'user_id': 'nunique'}),\n",
    "    on=['date', 'channel'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем параметр ad_costs — траты на рекламу\n",
    "def get_cac_profiles(sessions, orders, events, ad_costs, event_names=[]):\n",
    "\n",
    "    # сортируем сессии по ID пользователя и дате привлечения\n",
    "    # группируем по ID и находим параметры первых посещений\n",
    "    profiles = (\n",
    "        sessions.sort_values(by=['user_id', 'session_start'])\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            {\n",
    "                'session_start': 'first',\n",
    "                'channel': 'first',\n",
    "                'device': 'first',\n",
    "                'region': 'first',\n",
    "            }\n",
    "        )\n",
    "         # время первого посещения назовём first_ts\n",
    "        .rename(columns={'session_start': 'first_ts'})\n",
    "        .reset_index()  # возвращаем user_id из индекса\n",
    "    )\n",
    "\n",
    "    # для когортного анализа определяем дату первого посещения\n",
    "    # и первый день месяца, в который это посещение произошло\n",
    "    profiles['date'] = profiles['first_ts'].dt.date\n",
    "    profiles['month'] = profiles['first_ts'].astype('datetime64[M]')\n",
    "\n",
    "    # добавляем признак платящих пользователей\n",
    "    profiles['payer'] = profiles['user_id'].isin(orders['user_id'].unique())\n",
    "\n",
    "    # добавляем флаги для всех событий из event_names\n",
    "    for event in event_names:\n",
    "        if event in events['event_name'].unique():\n",
    "            # проверяем, встречается ли каждый пользователь\n",
    "            # среди тех, кто совершил событие event\n",
    "            profiles[event] = profiles['user_id'].isin(\n",
    "                events.query('event_name == @event')['user_id'].unique()\n",
    "            )\n",
    "\n",
    "    # считаем количество уникальных пользователей\n",
    "    # с одинаковыми источником и датой привлечения\n",
    "    new_users = (\n",
    "        profiles.groupby(['date', 'channel'])\n",
    "        .agg({'user_id': 'nunique'})\n",
    "         # столбец с числом пользователей назовём unique_users\n",
    "        .rename(columns={'user_id': 'unique_users'})\n",
    "        .reset_index()  # возвращаем dt и channel из индексов\n",
    "    )\n",
    "\n",
    "    # объединяем траты на рекламу и число привлечённых пользователей\n",
    "    # по дате и каналу привлечения\n",
    "    ad_costs = ad_costs.merge(new_users, on=['date', 'channel'], how='left')\n",
    "\n",
    "    # делим рекламные расходы на число привлечённых пользователей\n",
    "    # результаты сохраним в столбец acquisition_cost (CAC)\n",
    "    ad_costs['acquisition_cost'] = ad_costs['costs'] / ad_costs['unique_users']\n",
    "\n",
    "    # добавим стоимость привлечения в профили\n",
    "    profiles = profiles.merge(\n",
    "        ad_costs[['date', 'channel', 'acquisition_cost']],\n",
    "        on=['date', 'channel'],\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "    # органические пользователи не связаны с данными о рекламе,\n",
    "    # поэтому в столбце acquisition_cost у них значения NaN\n",
    "    # заменим их на ноль, ведь стоимость привлечения равна нулю\n",
    "    profiles['acquisition_cost'] = profiles['acquisition_cost'].fillna(0)\n",
    "    \n",
    "    return profiles  # возвращаем профили с CAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(URL + 'events.csv')\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ae4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = get_cac_profiles(sessions, orders, events, costs)\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb3025",
   "metadata": {},
   "source": [
    "Выясним, как меняется стоимость привлечения для каждого источника от когорты к когорте.\n",
    "\n",
    "Для этого построим сводную таблицу, в которой:\n",
    "- названиями строк будут даты привлечения пользователей,\n",
    "- названиями столбцов — каналы привлечения,\n",
    "- а значениями — средний CAC,\n",
    "\n",
    "и построим по ней график истории изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac45365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим график истории CAC по каналам привлечения\n",
    "\n",
    "profiles.pivot_table(\n",
    "    index='date', columns='channel', values='acquisition_cost', aggfunc='mean'\n",
    ").plot(figsize=(10, 5), grid=True)\n",
    "plt.title('Динамика CAC по каналам привлечения')\n",
    "plt.xlabel('Дата привлечения')\n",
    "plt.ylabel('CAC, $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4705162",
   "metadata": {},
   "source": [
    "### ROI Return Of Investments\n",
    "\n",
    "Когда сравниваешь много когорт по LTV и CAC одновременно - то линий вдвое больше чем надо. Ты по сути хочешь сравнить эффективность, окупаемость. Главный принцип успешных инвестиций — затраты не должны превышать полученный в результате доход.\n",
    "\n",
    "ROI, или Return On Investment, — окупаемость инвестиций. В экономике одного покупателя эта метрика показывает, на сколько процентов LTV превысил CAC. Ещё говорят: на сколько процентов «окупились» клиенты.\n",
    "\n",
    "ROI = LTV / CAC = выручка с когорты / расходы на привлечение когорты\n",
    "\n",
    "Почему не включаем в формулу себестоимость товаров? Потому что её учёт и подсчёт намного сложнее, требует неоправданно много усилий и времени.\n",
    "\n",
    "_CAC и ROI (записанный на месте LTV)_\n",
    "![](https://pictures.s3.yandex.net/resources/ROI_1_1620494905.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898818b8",
   "metadata": {},
   "source": [
    "#### Алгоритм\n",
    "\n",
    "- выбрать признак\n",
    "- сосчитать LTV по признаку\n",
    "- сосчитать CAC по признаку\n",
    "- разделить таблицу LTV на серию CAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f057527",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03851c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv_raw, ltv, ltv_hist = get_ltv(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 7, dimensions=['channel']\n",
    ")\n",
    "\n",
    "display(ltv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# кривые LTV\n",
    "report = ltv.drop(columns=['cohort_size'])\n",
    "report.T.plot(grid=True, figsize=(10, 5), xticks=list(report.columns))\n",
    "plt.title('LTV с разбивкой по источникам')\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.ylabel('LTV, $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa70b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11169623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# самая поздняя подходящая дата привлечения из событий LTV\n",
    "max_acquisition_dt = ltv_raw['date'].max()\n",
    "# выбиваем только профили, которые старше этой даты\n",
    "ltv_profiles = profiles.query('date <= @max_acquisition_dt')\n",
    "# сколько пользователей в каждый лайфтайм?\n",
    "ltv_profiles.groupby('date').agg({'user_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c738375",
   "metadata": {},
   "outputs": [],
   "source": [
    "cac = (\n",
    "    ltv_profiles.groupby('channel')\n",
    "    .agg({'acquisition_cost': 'mean'})\n",
    "    .rename(columns={'acquisition_cost': 'cac'})\n",
    ")\n",
    "\n",
    "cac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ltv.div(cac['cac'], axis=0)\n",
    "roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db988d8d",
   "metadata": {},
   "source": [
    "Столбец c размерами когорт «сломался», а ROI органических пользователей устремился в бесконечность — из-за деления на ноль.\n",
    "\n",
    "Затраты на привлечение органических пользователей нулевые, поэтому они всегда окупаются. А раз так, исключим их — удалим из результата все строки, в которых размер когорты равен бесконечности, применяя метод `isin()` и оператор `~` (\"not\"). Сравнивать значения с бесконечностью в Python позволяет переменная `inf` из библиотеки `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1806435",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = roi[~roi['cohort_size'].isin([np.inf])]\n",
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.loc[:, 'cohort_size'] = ltv.loc[:, 'cohort_size']\n",
    "roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d849b5",
   "metadata": {},
   "source": [
    "Таблица ROI готова.\n",
    "\n",
    "Построим кривые ROI и добавим на график уровень окупаемости, вызвав функцию [`axhline()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axhline.html) из библиотеки `matplotlib`:\n",
    "\n",
    "- `y` — координата линии по вертикальной оси,\n",
    "- `color` — цвет линии,\n",
    "- `linestyle` — стиль линии,\n",
    "- `label` — подпись.\n",
    "\n",
    "Уровень окупаемости установим на уровне `1`, линию сделаем красной (`color='red'`) и пунктирной (`linestyle='--'`). Чтобы добавить её в легенду, вызовем метод [`legend()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html) библиотеки `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = roi.drop(columns=['cohort_size'])\n",
    "report.T.plot(grid=True, figsize=(10, 5), xticks=list(report.columns.values))\n",
    "\n",
    "plt.title('ROI с разбивкой по каналам привлечения')\n",
    "plt.ylabel('ROI')\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.axhline(y=1, color='red', linestyle='--', label='Уровень окупаемости')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e682643",
   "metadata": {},
   "source": [
    "Судя по графику, реклама в «Яндексе» окупилась в среднем на 200%, а вот реклама в `AnotherSource` не окупилась вовсе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07b7a9",
   "metadata": {},
   "source": [
    "### Функция для расчёта LTV, CAC и ROI\n",
    "\n",
    "Чтобы всякий раз не повторять действия выше при расчёте ROI по новым данным, добавим их в функцию для расчёта пожизненной ценности `get_ltv()`:\n",
    "\n",
    "- рассчитаем CAC,\n",
    "- разделим LTV на CAC,\n",
    "- удалим строки с бесконечным ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltv(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # исключаем пользователей, не «доживших» до горизонта анализа\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - datetime.timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('date <= @last_suitable_acquisition_date')\n",
    "    # добавляем данные о покупках в профили\n",
    "    result_raw = result_raw.merge(\n",
    "        purchases[['user_id', 'event_dt', 'revenue']], on='user_id', how='left'\n",
    "    )\n",
    "    # рассчитываем лайфтайм пользователя для каждой покупки\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "    # группируем по cohort, если в dimensions ничего нет\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # функция группировки по желаемым признакам\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        # строим «треугольную» таблицу выручки\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='revenue', aggfunc='sum'\n",
    "        )\n",
    "        # находим сумму выручки с накоплением\n",
    "        result = result.fillna(0).cumsum(axis=1)\n",
    "        # вычисляем размеры когорт\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        # объединяем размеры когорт и таблицу выручки\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # считаем LTV: делим каждую «ячейку» в строке на размер когорты\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        # исключаем все лайфтаймы, превышающие горизонт анализа\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        # восстанавливаем размеры когорт\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # сохраняем в датафрейм данные пользователей и значения CAC, \n",
    "        # добавив параметры из dimensions\n",
    "        cac = df[['user_id', 'acquisition_cost'] + dims].drop_duplicates()\n",
    "\n",
    "        # считаем средний CAC по параметрам из dimensions\n",
    "        cac = (\n",
    "            cac.groupby(dims)\n",
    "            .agg({'acquisition_cost': 'mean'})\n",
    "            .rename(columns={'acquisition_cost': 'cac'})\n",
    "        )\n",
    "\n",
    "        # считаем ROI: делим LTV на CAC\n",
    "        roi = result.div(cac['cac'], axis=0)\n",
    "\n",
    "        # удаляем строки с бесконечным ROI\n",
    "        roi = roi[~roi['cohort_size'].isin([np.inf])]\n",
    "\n",
    "        # восстанавливаем размеры когорт в таблице ROI\n",
    "        roi['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # добавляем CAC в таблицу ROI\n",
    "        roi['cac'] = cac['cac']\n",
    "\n",
    "        # в финальной таблице оставляем размеры когорт, CAC\n",
    "        # и ROI в лайфтаймы, не превышающие горизонт анализа\n",
    "        roi = roi[['cohort_size', 'cac'] + list(range(horizon_days))]\n",
    "\n",
    "        # возвращаем таблицы LTV и ROI\n",
    "        return result, roi\n",
    "\n",
    "    # получаем таблицы LTV и ROI\n",
    "    result_grouped, roi_grouped = group_by_dimensions(\n",
    "        result_raw, dimensions, horizon_days\n",
    "    )\n",
    "\n",
    "    # для таблиц динамики убираем 'cohort' из dimensions\n",
    "    if 'cohort' in dimensions:\n",
    "        dimensions = []\n",
    "\n",
    "    # получаем таблицы динамики LTV и ROI\n",
    "    result_in_time, roi_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['date'], horizon_days\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        result_raw,  # сырые данные\n",
    "        result_grouped,  # таблица LTV\n",
    "        result_in_time,  # таблица динамики LTV\n",
    "        roi_grouped,  # таблица ROI\n",
    "        roi_in_time,  # таблица динамики ROI\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8977a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# рассчитываем LTV и ROI\n",
    "\n",
    "ltv_raw, ltv, ltv_history, roi, roi_history = get_ltv(\n",
    "    profiles, orders, datetime.date(2019, 5, 13), 7, dimensions=['channel']\n",
    ")\n",
    "\n",
    "roi  # таблица ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_history.pivot_table(\n",
    "    index='date', columns='channel', values='cac', aggfunc='mean'\n",
    ").plot(grid=True, figsize=(10, 5))\n",
    "plt.title('Динамика CAC по источникам')\n",
    "plt.xlabel('Даты привлечения')\n",
    "plt.ylabel('CAC, $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ef57d",
   "metadata": {},
   "source": [
    "Кроме того, таблица динамики ROI позволяет оценить изменения окупаемости в зависимости от канала и даты привлечения.\n",
    "\n",
    "Построим график динамики ROI первого дня с разбивкой по каналам.\n",
    "\n",
    "Для этого создадим сводную таблицу, в которой\n",
    "- названиями строк окажутся даты привлечения пользователей,\n",
    "- названиями столбцов — каналы,\n",
    "- а значениями — среднее значение ROI по столбцу 0, в котором лежат данные за нулевой лайфтайм, или первый день «жизни»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de15445",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_history.pivot_table(\n",
    "    index='date', columns='channel', values=0, aggfunc='mean'\n",
    ").plot(grid=True, figsize=(10, 5))\n",
    "plt.title('Динамика окупаемости в первый день когорт')\n",
    "plt.xlabel('Даты привлечения')\n",
    "plt.ylabel('ROI')\n",
    "plt.axhline(label='Уровень окупаемости', y=1, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4f707",
   "metadata": {},
   "source": [
    "График показывает, что реклама в Яндексе всегда окупалась в первый же день, реклама в ином источнике - никогда."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca31a6c",
   "metadata": {},
   "source": [
    "### Как проверить правдоподобость результата\n",
    "\n",
    "Причины неверных результатов:\n",
    "- \"сломанные\" данные;\n",
    "- неучтённые момент и горизонт анализа;\n",
    "- ошибки алгоритма;\n",
    "- и другое.\n",
    "\n",
    "#### Удержание Retention Rate:\n",
    "\n",
    "- Сумма размеров когорт равна числу новых клиентов в изучаемый период.\n",
    "- Сумма размеров платящих когорт равна числу покупателей в изучаемый период.\n",
    "- Удержание убывает по [экспоненте](https://ru.wikipedia.org/wiki/Экспонента).\n",
    "- Удержание неплатящих убывает быстрее, чем удержание платящих."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7199770",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = profiles.query(\n",
    "     # в профилях находим пользователей, привлечённых с 1 по 5 мая\n",
    "    'datetime.date(2019, 5, 1) <= date <= datetime.date(2019, 5, 7)'\n",
    ")\n",
    "print(\n",
    "    # считаем уникальных пользователей в профилях и складываем размеры когорт\n",
    "    'Общее количество новых пользователей: {} {}'.format(\n",
    "        len(report['user_id'].unique()),\n",
    "        0 # retention['cohort_size'].sum()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = profiles.query(\n",
    "    # в профилях находим платящих пользователей, привлечённых с 1 по 5 мая\n",
    "    'datetime.date(2019, 5, 1) <= date <= datetime.date(2019, 5, 7) and payer == True'\n",
    ")\n",
    "print(\n",
    "    # считаем уникальных платящих пользователей в профилях \n",
    "    # и складываем размеры платящих когорт\n",
    "    'Общее количество новых покупателей: {} {}'.format(\n",
    "        len(report['user_id'].unique()),\n",
    "        0 #retention.query('payer == True')['cohort_size'].sum(),\n",
    "    )  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc715f6",
   "metadata": {},
   "source": [
    "Проверяем поведение графиков. Эталонные графики:\n",
    "\n",
    "![](https://pictures.s3.yandex.net/resources/graph_5_1620501686.png)\n",
    "\n",
    "Фактические:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab641c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention.T.plot(grid=True, xticks=list(retention.columns.values), figsize=(15, 5))\n",
    "plt.title('Удержание с разбивкой по покупкам')\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.ylabel('Доля от всей когорты')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8af5a",
   "metadata": {},
   "source": [
    "Похоже, всё в порядке:\n",
    "- кривая удержания платящих выше;\n",
    "- обе кривые снижаются.\n",
    "\n",
    "#### Конверсия Conversion Rate\n",
    "\n",
    "При расчёте конверсии удостоверьтесь, что:\n",
    "- сумма когорт равна общему числу новых клиентов за выбранный период;\n",
    "- количество новых покупателей равно числу клиентов, умноженному на конверсию;\n",
    "- кривая конверсии плавно растёт от нуля к лимиту единицы, без единого снижения;\n",
    "- не превышает единицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_history['cohort_size'].sum() == profiles.query(\n",
    "    'datetime.date(2019, 5, 1) <= date <= datetime.date(2019, 5, 8)'\n",
    ")['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46e9de",
   "metadata": {},
   "source": [
    "![](https://pictures.s3.yandex.net/resources/graph_7_1620501905.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = conversion.drop(columns={'cohort_size'})\n",
    "report.T.plot(grid=True, xticks=list(report.columns.values), figsize=(12, 5))\n",
    "plt.title('Кривая конверсии')\n",
    "plt.xlabel('Лайфтайм')\n",
    "plt.ylabel('Доля в размере когорты')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# только значения больше единицы\n",
    "\n",
    "report[report > 1].fillna('')  # скрывает значения ниже нуля"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f97c4",
   "metadata": {},
   "source": [
    "#### Полная ценность пользователя LTV\n",
    "\n",
    "- Сумма размеров когорт равна общему числу новых клиентов в изучаемый период.\n",
    "- Кривая LTV плавно растёт от нуля с возможным пересечением единицы.\n",
    "- Кривая LTV не снижается.\n",
    "- Общая стоимость покупок новых клиентов равна максимальному LTV, умноженному на число новых клиентов.\n",
    "\n",
    "![](https://pictures.s3.yandex.net/resources/graph_6_1620502104.png)\n",
    "\n",
    "Как и конверсия, LTV повышается по экспоненте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea8376",
   "metadata": {},
   "source": [
    "#### Стоимость привлечения клиента CAC\n",
    "\n",
    "- CAC из таблицы ROI, умноженный на размер когорты, равен сумме рекламных трат за изучаемый период."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c7c25",
   "metadata": {},
   "source": [
    "#### Возврат на инвестиции, или ROI\n",
    "\n",
    "Если вы проверили LTV и САС, то за ROI можно не волноваться: раз все компоненты верны, верен и результат.\n",
    "\n",
    "Единственное, на что стоит обратить внимание, — порядок значений.\n",
    "\n",
    "Реалистичный ROI находится в пределах от 0 до 3. Ведь вполне может быть, что затраты на привлечение не окупились — тогда ROI меньше 100%; или наоборот, окупились с лихвой — тогда ROI больше 100%. Если же затраты на привлечение окупились более чем на 300%, то перед вами либо маркетинговое чудо, либо ошибка в расчётах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4bedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
